{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NWOgvbQj-kF5"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# BAGIAN 1: IMPORT LIBRARY & LOAD DATA\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqvD6pSbOu3t",
        "outputId": "95d98e66-932e-473e-b728-32629f8eaa2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Sedang membaca file (ini mungkin memakan waktu untuk 200k baris)...\n",
            "   Sukses! Total data: 275088 baris.\n"
          ]
        }
      ],
      "source": [
        "# Update path untuk local - letakkan file Excel di folder yang sama dengan notebook\n",
        "# Atau sesuaikan path sesuai lokasi file Anda\n",
        "import os\n",
        "file_path = 'SPE-OPT-31122025.xlsx'  # File di folder yang sama dengan notebook\n",
        "# Alternatif: file_path = r'D:\\ICON+\\Prediksi Flow Produk\\SPE-OPT-31122025.xlsx'\n",
        "\n",
        "print(\"1. Sedang membaca file (ini mungkin memakan waktu untuk 200k baris)...\")\n",
        "try:\n",
        "    # Jika file csv, ganti read_excel jadi read_csv\n",
        "    df = pd.read_excel(file_path)\n",
        "    print(f\"   Sukses! Total data: {len(df)} baris.\")\n",
        "except Exception as e:\n",
        "    print(f\"   Error: {e}\")\n",
        "    print(f\"   Pastikan file 'SPE-OPT-31122025.xlsx' ada di folder yang sama dengan notebook ini.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQEJPGvlPZUo",
        "outputId": "45aff20a-8181-4c3b-d48d-189fb61a5b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2. Membersihkan & Menambah Fitur Canggih...\n",
            "   Menambahkan fitur lanjutan...\n",
            "   Menambahkan rolling statistics...\n",
            "   Menambahkan fitur popularitas produk...\n",
            "   Menambahkan frekuensi pembelian customer...\n",
            "   Menambahkan fitur waktu lanjutan...\n",
            "   Menambahkan fitur perubahan harga...\n",
            "   Menambahkan affinity customer-produk...\n",
            "   Menambahkan affinity segmen-produk...\n",
            "   Menambahkan fitur normalisasi...\n",
            "   Data Ready! Total fitur: 48 kolom\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# BAGIAN 2: CLEANING & ADVANCED FEATURE ENGINEERING (MODIFIED)\n",
        "# ==========================================\n",
        "print(\"2. Membersihkan & Menambah Fitur Canggih...\")\n",
        "\n",
        "# Define columns (Added Price and Bandwidth)\n",
        "col_id = 'idPerusahaan'\n",
        "col_prod = 'namaProduk'\n",
        "col_date = 'tanggalAwalKontrak' # Or 'tanggalBuatPermohonan' if available\n",
        "col_segmen = 'segmenCustomer'\n",
        "col_sbu = 'sbuOwner'\n",
        "col_price = 'hargaPelanggan' # NEW\n",
        "col_bw = 'bandwidthBaru' # NEW\n",
        "\n",
        "# Select columns\n",
        "cols_to_use = [col_id, col_prod, col_date, col_segmen, col_sbu, col_price, col_bw]\n",
        "df_ml = df[cols_to_use].copy()\n",
        "\n",
        "# 1. Clean Data Types\n",
        "df_ml[col_date] = pd.to_datetime(df_ml[col_date], errors='coerce')\n",
        "\n",
        "# Clean Price (Remove commas/dots if string)\n",
        "def clean_currency(x):\n",
        "    try:\n",
        "        return float(str(x).replace(',', '.').replace('nan', '0'))\n",
        "    except:\n",
        "        return 0\n",
        "df_ml[col_price] = df_ml[col_price].apply(clean_currency)\n",
        "df_ml[col_bw] = pd.to_numeric(df_ml[col_bw], errors='coerce').fillna(0)\n",
        "\n",
        "# 2. Sort is CRITICAL for flow\n",
        "df_ml.dropna(subset=[col_prod, col_date], inplace=True)\n",
        "df_ml.sort_values(by=[col_id, col_date], inplace=True)\n",
        "\n",
        "# 3. Create \"Flow\" Features (The Magic Sauce)\n",
        "grouped = df_ml.groupby(col_id)\n",
        "\n",
        "# Feature A: Previous Product (What did they buy BEFORE this?)\n",
        "df_ml['Prev_Product'] = grouped[col_prod].shift(1).fillna('New Customer')\n",
        "\n",
        "# Feature B: Days Since Last Order (Gap time)\n",
        "df_ml['Prev_Date'] = grouped[col_date].shift(1)\n",
        "df_ml['Days_Since_Last'] = (df_ml[col_date] - df_ml['Prev_Date']).dt.days.fillna(-1)\n",
        "\n",
        "# Feature C: Order Sequence (1st order, 2nd order, etc.)\n",
        "df_ml['Order_Seq'] = grouped.cumcount() + 1\n",
        "\n",
        "# 4. Create Target (Next Product)\n",
        "df_ml['Next_Product'] = grouped[col_prod].shift(-1)\n",
        "\n",
        "# Filter valid data for training\n",
        "train_data_raw = df_ml.dropna(subset=['Next_Product']).copy()\n",
        "latest_status = df_ml.groupby(col_id).tail(1).copy()\n",
        "\n",
        "# Filter Rare Products (Same as your code)\n",
        "target_counts = train_data_raw['Next_Product'].value_counts()\n",
        "valid_targets = target_counts[target_counts >= 2].index\n",
        "train_data = train_data_raw[train_data_raw['Next_Product'].isin(valid_targets)].copy()\n",
        "\n",
        "# ==========================================\n",
        "# ADVANCED FEATURE ENGINEERING (NEW)\n",
        "# ==========================================\n",
        "print(\"   Menambahkan fitur lanjutan...\")\n",
        "\n",
        "# 1. Time-based features\n",
        "train_data['Year'] = train_data[col_date].dt.year\n",
        "train_data['Month'] = train_data[col_date].dt.month\n",
        "train_data['Quarter'] = train_data[col_date].dt.quarter\n",
        "train_data['DayOfWeek'] = train_data[col_date].dt.dayofweek\n",
        "train_data['IsWeekend'] = (train_data['DayOfWeek'] >= 5).astype(int)\n",
        "\n",
        "# 2. Customer behavior aggregations\n",
        "customer_stats = train_data.groupby(col_id).agg({\n",
        "    col_price: ['mean', 'std', 'min', 'max', 'count'],\n",
        "    col_bw: ['mean', 'std', 'min', 'max'],\n",
        "    'Days_Since_Last': ['mean', 'std'],\n",
        "    'Order_Seq': 'max'\n",
        "}).reset_index()\n",
        "\n",
        "customer_stats.columns = [col_id] + [f'Customer_{col[0]}_{col[1]}' if col[1] else col[0] for col in customer_stats.columns[1:]]\n",
        "train_data = train_data.merge(customer_stats, on=col_id, how='left')\n",
        "\n",
        "# 3. Product transition patterns (how often does this transition happen?)\n",
        "train_data['Transition'] = train_data[col_prod].astype(str) + '_TO_' + train_data['Prev_Product'].astype(str)\n",
        "transition_counts = train_data['Transition'].value_counts().to_dict()\n",
        "train_data['Transition_Frequency'] = train_data['Transition'].map(transition_counts)\n",
        "\n",
        "# 4. Price and bandwidth ratios\n",
        "train_data['Price_Ratio'] = train_data[col_price] / (train_data['Customer_hargaPelanggan_mean'] + 1e-6)\n",
        "train_data['BW_Ratio'] = train_data[col_bw] / (train_data['Customer_bandwidthBaru_mean'] + 1e-6)\n",
        "\n",
        "# 5. Interaction features\n",
        "train_data['Price_BW_Interaction'] = train_data[col_price] * train_data[col_bw]\n",
        "train_data['Days_Order_Interaction'] = train_data['Days_Since_Last'] * train_data['Order_Seq']\n",
        "\n",
        "# 6. Customer loyalty/recency features\n",
        "train_data['Is_Repeat_Customer'] = (train_data['Order_Seq'] > 1).astype(int)\n",
        "train_data['Is_Long_Gap'] = (train_data['Days_Since_Last'] > train_data['Customer_Days_Since_Last_mean']).astype(int)\n",
        "\n",
        "# 7. Segment-SBU interaction\n",
        "train_data['Segmen_SBU'] = train_data[col_segmen].astype(str) + '_' + train_data[col_sbu].astype(str)\n",
        "\n",
        "# 8. ADVANCED FEATURES - Rolling Statistics (Moving Window)\n",
        "print(\"   Menambahkan rolling statistics...\")\n",
        "train_data_sorted = train_data.sort_values(by=[col_id, col_date])\n",
        "grouped_sorted = train_data_sorted.groupby(col_id)\n",
        "\n",
        "# Rolling mean untuk price dan bandwidth (window 3)\n",
        "train_data_sorted['Price_Rolling_Mean_3'] = grouped_sorted[col_price].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "train_data_sorted['BW_Rolling_Mean_3'] = grouped_sorted[col_bw].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "train_data_sorted['Days_Rolling_Mean_3'] = grouped_sorted['Days_Since_Last'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "\n",
        "# 9. Product Popularity Features\n",
        "print(\"   Menambahkan fitur popularitas produk...\")\n",
        "product_popularity = train_data[col_prod].value_counts().to_dict()\n",
        "train_data['Product_Popularity'] = train_data[col_prod].map(product_popularity)\n",
        "train_data['Prev_Product_Popularity'] = train_data['Prev_Product'].map(product_popularity).fillna(0)\n",
        "\n",
        "# 10. Customer Purchase Frequency\n",
        "print(\"   Menambahkan frekuensi pembelian customer...\")\n",
        "customer_frequency = train_data.groupby(col_id).size().to_dict()\n",
        "train_data['Customer_Frequency'] = train_data[col_id].map(customer_frequency)\n",
        "\n",
        "# Simpan dictionary untuk digunakan di prediksi (global scope)\n",
        "globals()['product_popularity'] = product_popularity\n",
        "globals()['customer_frequency'] = customer_frequency\n",
        "\n",
        "# 11. Time-based Advanced Features\n",
        "print(\"   Menambahkan fitur waktu lanjutan...\")\n",
        "train_data['Days_Since_Year_Start'] = (train_data[col_date] - pd.to_datetime(train_data['Year'].astype(str) + '-01-01')).dt.days\n",
        "train_data['Days_Since_Month_Start'] = (train_data[col_date] - pd.to_datetime(train_data[col_date].dt.to_period('M').astype(str))).dt.days\n",
        "train_data['Is_Month_End'] = (train_data[col_date].dt.day > 25).astype(int)\n",
        "train_data['Is_Quarter_End'] = train_data['Month'].isin([3, 6, 9, 12]).astype(int)\n",
        "\n",
        "# 12. Price Change Features\n",
        "print(\"   Menambahkan fitur perubahan harga...\")\n",
        "train_data_sorted['Price_Change'] = grouped_sorted[col_price].diff().fillna(0)\n",
        "train_data_sorted['Price_Change_Pct'] = grouped_sorted[col_price].pct_change().fillna(0)\n",
        "train_data_sorted['BW_Change'] = grouped_sorted[col_bw].diff().fillna(0)\n",
        "\n",
        "# Merge rolling features back\n",
        "train_data = train_data_sorted.copy()\n",
        "\n",
        "# 13. Customer-Product Affinity (berapa kali customer beli produk ini sebelumnya)\n",
        "print(\"   Menambahkan affinity customer-produk...\")\n",
        "customer_product_count = train_data.groupby([col_id, col_prod]).size().reset_index(name='Customer_Product_Count')\n",
        "train_data = train_data.merge(customer_product_count, on=[col_id, col_prod], how='left')\n",
        "train_data['Customer_Product_Count'] = train_data['Customer_Product_Count'].fillna(0)\n",
        "\n",
        "# 14. Segment-Product Affinity\n",
        "print(\"   Menambahkan affinity segmen-produk...\")\n",
        "segmen_product_count = train_data.groupby([col_segmen, col_prod]).size().reset_index(name='Segmen_Product_Count')\n",
        "train_data = train_data.merge(segmen_product_count, on=[col_segmen, col_prod], how='left')\n",
        "train_data['Segmen_Product_Count'] = train_data['Segmen_Product_Count'].fillna(0)\n",
        "\n",
        "# Simpan untuk digunakan di prediksi (global scope)\n",
        "globals()['customer_product_count'] = customer_product_count\n",
        "globals()['segmen_product_count'] = segmen_product_count\n",
        "\n",
        "# 15. Normalized Features (untuk membantu model)\n",
        "print(\"   Menambahkan fitur normalisasi...\")\n",
        "train_data['Order_Seq_Normalized'] = train_data['Order_Seq'] / (train_data['Customer_Order_Seq_max'] + 1e-6)\n",
        "train_data['Days_Since_Last_Normalized'] = train_data['Days_Since_Last'] / (train_data['Customer_Days_Since_Last_mean'] + 1e-6)\n",
        "\n",
        "# Fill NaN values from aggregations\n",
        "train_data = train_data.fillna(0)\n",
        "\n",
        "print(f\"   Data Ready! Total fitur: {len(train_data.columns)} kolom\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uju8tcWtQst4",
        "outputId": "fdf3979d-2122-493c-c068-d4d481b86bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3. Encoding Data & Persiapan Fitur...\n",
            "   Encoding Selesai!\n",
            "   Fitur Siap: Produk, History Produk, Harga, Durasi, Segmen, dll.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# BAGIAN 3: ENCODING (PERBAIKAN - MENANGANI DATA HISTORY)\n",
        "# ==========================================\n",
        "print(\"3. Encoding Data & Persiapan Fitur...\")\n",
        "\n",
        "# 1. Inisialisasi Encoders\n",
        "le_prod = LabelEncoder()\n",
        "le_prev_prod = LabelEncoder()\n",
        "le_segmen = LabelEncoder()\n",
        "le_sbu = LabelEncoder()\n",
        "le_target = LabelEncoder()\n",
        "\n",
        "# 2. Fit Encoders (Belajar dari seluruh kemungkinan data)\n",
        "# Gabung Produk saat ini + Previous + Next supaya encoder tahu semua jenis produk\n",
        "all_products = pd.concat([\n",
        "    df_ml[col_prod],\n",
        "    df_ml['Prev_Product'],\n",
        "    df_ml['Next_Product'].dropna()\n",
        "]).unique().astype(str)\n",
        "\n",
        "le_prod.fit(all_products)\n",
        "le_prev_prod.fit(all_products) # Gunakan list produk yang sama\n",
        "le_target.fit(all_products)    # Gunakan list produk yang sama\n",
        "\n",
        "# Fit segmen & SBU\n",
        "le_segmen.fit(df_ml[col_segmen].astype(str))\n",
        "le_sbu.fit(df_ml[col_sbu].astype(str))\n",
        "\n",
        "# 3. Transformasi Data Training (Ubah teks jadi angka)\n",
        "# Kita buat kolom baru berakhiran '_code'\n",
        "train_data['prod_code'] = le_prod.transform(train_data[col_prod].astype(str))\n",
        "train_data['prev_prod_code'] = le_prev_prod.transform(train_data['Prev_Product'].astype(str))\n",
        "train_data['segmen_code'] = le_segmen.transform(train_data[col_segmen].astype(str))\n",
        "train_data['sbu_code'] = le_sbu.transform(train_data[col_sbu].astype(str))\n",
        "train_data['target_code'] = le_target.transform(train_data['Next_Product'].astype(str))\n",
        "\n",
        "print(\"   Encoding Selesai!\")\n",
        "print(\"   Fitur Siap: Produk, History Produk, Harga, Durasi, Segmen, dll.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "5Jt-EaNkQ0SY",
        "outputId": "b97feab4-c19d-4a0a-9f71-a27cb0a5989a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "4. Training XGBoost dengan Fitur Lengkap...\n",
            "   Step 1: Encoding fitur tambahan...\n",
            "   ✓ Encoding selesai\n",
            "   Step 2: Menyiapkan fitur...\n",
            "   Warning: Fitur yang tidak ditemukan: ['Product_Popularity', 'Prev_Product_Popularity', 'Customer_Frequency', 'Days_Since_Year_Start', 'Days_Since_Month_Start', 'Is_Month_End', 'Is_Quarter_End']\n",
            "   ✓ Total fitur yang digunakan: 38\n",
            "   Step 3: Membersihkan data...\n",
            "   ✓ Data bersih\n",
            "   Step 4: Encoding target...\n",
            "   ✓ Target encoded, jumlah kelas: 211\n",
            "   Step 5: Membagi data training dan test...\n",
            "   ✓ Data split dengan stratify\n",
            "   Data training: 180338, Data test: 45085\n",
            "   Step 6: Training model dengan parameter yang lebih optimal...\n",
            "   ✓ Model berhasil dilatih dengan 600 iterasi\n",
            "   ✓ Training selesai!\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# BAGIAN 4: TRAINING XGBOOST DENGAN FITUR LENGKAP\n",
        "# ==========================================\n",
        "print(\"\\n4. Training XGBoost dengan Fitur Lengkap...\")\n",
        "\n",
        "# Pastikan semua import dan variabel tersedia\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Pastikan variabel dari cell sebelumnya tersedia\n",
        "required_vars = ['train_data', 'col_price', 'col_bw', 'col_id', 'col_prod', 'col_date', 'col_segmen', 'col_sbu']\n",
        "missing_vars = [v for v in required_vars if v not in globals()]\n",
        "if missing_vars:\n",
        "    raise Exception(f\"ERROR: Variabel berikut tidak ditemukan: {missing_vars}. Pastikan Cell 2 dan 3 sudah dijalankan!\")\n",
        "\n",
        "try:\n",
        "    # 1. Encoding fitur tambahan\n",
        "    print(\"   Step 1: Encoding fitur tambahan...\")\n",
        "    le_segmen_sbu = LabelEncoder()\n",
        "    le_transition = LabelEncoder()\n",
        "\n",
        "    # Encode interaction features\n",
        "    train_data['segmen_sbu_code'] = le_segmen_sbu.fit_transform(train_data['Segmen_SBU'].astype(str))\n",
        "    train_data['transition_code'] = le_transition.fit_transform(train_data['Transition'].astype(str))\n",
        "    print(\"   ✓ Encoding selesai\")\n",
        "\n",
        "    # 2. Definisi Fitur Lengkap (X) - Menggunakan semua fitur yang sudah di-engineer\n",
        "    print(\"   Step 2: Menyiapkan fitur...\")\n",
        "    features = [\n",
        "        'prod_code',\n",
        "        'prev_prod_code',\n",
        "        'segmen_code',\n",
        "        'sbu_code',\n",
        "        'segmen_sbu_code',\n",
        "        'Days_Since_Last',\n",
        "        col_price,\n",
        "        col_bw,\n",
        "        'Order_Seq',\n",
        "        'Year',\n",
        "        'Month',\n",
        "        'Quarter',\n",
        "        'DayOfWeek',\n",
        "        'IsWeekend',\n",
        "        'Customer_hargaPelanggan_mean',\n",
        "        'Customer_hargaPelanggan_std',\n",
        "        'Customer_bandwidthBaru_mean',\n",
        "        'Customer_bandwidthBaru_std',\n",
        "        'Customer_Days_Since_Last_mean',\n",
        "        'Customer_Order_Seq_max',\n",
        "        'Transition_Frequency',\n",
        "        'Price_Ratio',\n",
        "        'BW_Ratio',\n",
        "        'Price_BW_Interaction',\n",
        "        'Days_Order_Interaction',\n",
        "        'Is_Repeat_Customer',\n",
        "        'Is_Long_Gap',\n",
        "        'transition_code',\n",
        "        # NEW ADVANCED FEATURES\n",
        "        'Price_Rolling_Mean_3',\n",
        "        'BW_Rolling_Mean_3',\n",
        "        'Days_Rolling_Mean_3',\n",
        "        'Product_Popularity',\n",
        "        'Prev_Product_Popularity',\n",
        "        'Customer_Frequency',\n",
        "        'Days_Since_Year_Start',\n",
        "        'Days_Since_Month_Start',\n",
        "        'Is_Month_End',\n",
        "        'Is_Quarter_End',\n",
        "        'Price_Change',\n",
        "        'Price_Change_Pct',\n",
        "        'BW_Change',\n",
        "        'Customer_Product_Count',\n",
        "        'Segmen_Product_Count',\n",
        "        'Order_Seq_Normalized',\n",
        "        'Days_Since_Last_Normalized'\n",
        "    ]\n",
        "\n",
        "    # Filter features that exist in train_data\n",
        "    available_features = [f for f in features if f in train_data.columns]\n",
        "    missing_features = [f for f in features if f not in train_data.columns]\n",
        "    if missing_features:\n",
        "        print(f\"   Warning: Fitur yang tidak ditemukan: {missing_features}\")\n",
        "    \n",
        "    X = train_data[available_features].copy()\n",
        "    print(f\"   ✓ Total fitur yang digunakan: {len(available_features)}\")\n",
        "\n",
        "    # 3. Clean data - replace inf and NaN\n",
        "    print(\"   Step 3: Membersihkan data...\")\n",
        "    X = X.replace([np.inf, -np.inf], np.nan)\n",
        "    X = X.fillna(0)\n",
        "\n",
        "    # Check for any remaining issues\n",
        "    if X.isnull().any().any():\n",
        "        print(\"   Warning: Masih ada NaN, mengisi dengan 0...\")\n",
        "        X = X.fillna(0)\n",
        "    print(\"   ✓ Data bersih\")\n",
        "\n",
        "    # 4. KHUSUS TARGET (y): Buat Encoder Baru Setelah Filter\n",
        "    print(\"   Step 4: Encoding target...\")\n",
        "    le_target_final = LabelEncoder()\n",
        "    y = le_target_final.fit_transform(train_data['Next_Product'].astype(str))\n",
        "    print(f\"   ✓ Target encoded, jumlah kelas: {len(np.unique(y))}\")\n",
        "\n",
        "    # 5. Split Data dengan error handling untuk stratify\n",
        "    print(\"   Step 5: Membagi data training dan test...\")\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y,\n",
        "            test_size=0.2,\n",
        "            random_state=42,\n",
        "            stratify=y\n",
        "        )\n",
        "        print(f\"   ✓ Data split dengan stratify\")\n",
        "    except ValueError as e:\n",
        "        print(f\"   Warning: Stratify gagal ({e}), menggunakan split tanpa stratify...\")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y,\n",
        "            test_size=0.2,\n",
        "            random_state=42\n",
        "        )\n",
        "        print(f\"   ✓ Data split tanpa stratify\")\n",
        "    \n",
        "    print(f\"   Data training: {len(X_train)}, Data test: {len(X_test)}\")\n",
        "\n",
        "    # 6. Training Model dengan Parameter yang Dioptimalkan (IMPROVED)\n",
        "    print(\"   Step 6: Training model dengan parameter yang lebih optimal...\")\n",
        "    \n",
        "    # Handle class imbalance dengan scale_pos_weight\n",
        "    from collections import Counter\n",
        "    class_counts = Counter(y_train)\n",
        "    max_class_count = max(class_counts.values())\n",
        "    scale_pos_weight_dict = {cls: max_class_count / count for cls, count in class_counts.items()}\n",
        "    # XGBoost tidak support per-class weights untuk multi-class, jadi kita gunakan parameter lain\n",
        "    \n",
        "    model = xgb.XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        eval_metric='mlogloss',\n",
        "        n_estimators=600,  # Increased lebih banyak\n",
        "        max_depth=9,  # Increased untuk capture lebih kompleks\n",
        "        learning_rate=0.03,  # Reduced lebih jauh untuk better generalization\n",
        "        subsample=0.85,  # Slightly increased\n",
        "        colsample_bytree=0.85,  # Slightly increased\n",
        "        colsample_bylevel=0.8,  # NEW: subsample columns per level\n",
        "        min_child_weight=2,  # Reduced untuk lebih fleksibel\n",
        "        gamma=0.15,  # Increased untuk regularization\n",
        "        reg_alpha=0.2,  # Increased L1 regularization\n",
        "        reg_lambda=1.5,  # Increased L2 regularization\n",
        "        max_delta_step=1,  # Help with imbalanced classes\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        tree_method='hist'  # Faster and often better\n",
        "    )\n",
        "\n",
        "    # Fit model (tanpa eval_set untuk menghindari error)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"   ✓ Model berhasil dilatih dengan {model.n_estimators} iterasi\")\n",
        "    print(\"   ✓ Training selesai!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"   ERROR: {type(e).__name__}: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# OPSIONAL: HYPERPARAMETER TUNING (UNTUK AKURASI MAKSIMAL)\n",
        "# ==========================================\n",
        "# Uncomment bagian ini jika ingin melakukan tuning lebih lanjut\n",
        "# WARNING: Proses ini memakan waktu lama (bisa 30-60 menit)\n",
        "\n",
        "# print(\"\\n4b. Hyperparameter Tuning (Opsional - Memakan Waktu)...\")\n",
        "# \n",
        "# # Define parameter grid\n",
        "# param_grid = {\n",
        "#     'max_depth': [6, 8, 10],\n",
        "#     'learning_rate': [0.03, 0.05, 0.1],\n",
        "#     'n_estimators': [300, 500, 700],\n",
        "#     'subsample': [0.7, 0.8, 0.9],\n",
        "#     'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "#     'min_child_weight': [1, 3, 5],\n",
        "#     'gamma': [0, 0.1, 0.2],\n",
        "#     'reg_alpha': [0, 0.1, 0.5],\n",
        "#     'reg_lambda': [0.5, 1.0, 1.5]\n",
        "# }\n",
        "# \n",
        "# # Create base model\n",
        "# base_model = xgb.XGBClassifier(\n",
        "#     objective='multi:softprob',\n",
        "#     eval_metric='mlogloss',\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "# \n",
        "# # Randomized search (lebih cepat dari GridSearch)\n",
        "# random_search = RandomizedSearchCV(\n",
        "#     base_model,\n",
        "#     param_distributions=param_grid,\n",
        "#     n_iter=20,  # Jumlah kombinasi yang dicoba\n",
        "#     cv=3,  # 3-fold CV untuk mempercepat\n",
        "#     scoring='accuracy',\n",
        "#     n_jobs=-1,\n",
        "#     random_state=42,\n",
        "#     verbose=1\n",
        "# )\n",
        "# \n",
        "# random_search.fit(X_train, y_train)\n",
        "# \n",
        "# print(f\"\\n   Best Parameters: {random_search.best_params_}\")\n",
        "# print(f\"   Best CV Score: {random_search.best_score_*100:.2f}%\")\n",
        "# \n",
        "# # Gunakan model terbaik\n",
        "# model = random_search.best_estimator_\n",
        "# \n",
        "# # Fit ulang dengan early stopping\n",
        "# model.fit(\n",
        "#     X_train, y_train,\n",
        "#     eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "#     early_stopping_rounds=20,\n",
        "#     verbose=False\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbRog38FQ5s5",
        "outputId": "7dccb75a-b7d8-449a-b20e-9a812e29df0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "5. Evaluasi Model pada Data Test...\n",
            "   Akurasi Model (Test Set): 79.94%\n",
            "\n",
            "   Classification Report (Top 10 kelas):\n",
            "   (Menampilkan 10 kelas dengan sample terbanyak dari 198 total kelas)\n",
            "\n",
            "   Top 15 Fitur Paling Penting:\n",
            "                     feature  importance\n",
            "                   prod_code    0.176622\n",
            "             transition_code    0.094369\n",
            "              prev_prod_code    0.064246\n",
            "                 segmen_code    0.050245\n",
            "      Customer_Order_Seq_max    0.049218\n",
            "        Transition_Frequency    0.047204\n",
            "             segmen_sbu_code    0.047028\n",
            "        Segmen_Product_Count    0.046669\n",
            "      Customer_Product_Count    0.038998\n",
            " Customer_bandwidthBaru_mean    0.036975\n",
            "  Customer_bandwidthBaru_std    0.031130\n",
            "Customer_hargaPelanggan_mean    0.026722\n",
            " Customer_hargaPelanggan_std    0.025853\n",
            "                    sbu_code    0.024618\n",
            "                        Year    0.020363\n",
            "\n",
            "6. Menghasilkan Prediksi Akhir...\n",
            "   Melakukan prediksi...\n",
            "   Selesai! File tersimpan di: Hasil_Prediksi_Flow_Fixed.xlsx\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# BAGIAN 5: EVALUASI MODEL\n",
        "# ==========================================\n",
        "print(\"\\n5. Evaluasi Model pada Data Test...\")\n",
        "\n",
        "# Prediksi pada test set\n",
        "preds = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, preds)\n",
        "print(f\"   Akurasi Model (Test Set): {acc*100:.2f}%\")\n",
        "\n",
        "# Classification report untuk detail per kelas\n",
        "print(\"\\n   Classification Report (Top 10 kelas):\")\n",
        "unique_classes = np.unique(y_test)\n",
        "if len(unique_classes) > 10:\n",
        "    # Ambil 10 kelas dengan sample terbanyak\n",
        "    class_counts = pd.Series(y_test).value_counts().head(10)\n",
        "    top_classes = class_counts.index.tolist()\n",
        "    report = classification_report(y_test, preds, labels=top_classes, \n",
        "                                   target_names=[le_target_final.inverse_transform([c])[0] for c in top_classes],\n",
        "                                   zero_division=0, output_dict=True)\n",
        "    print(f\"   (Menampilkan 10 kelas dengan sample terbanyak dari {len(unique_classes)} total kelas)\")\n",
        "else:\n",
        "    report = classification_report(y_test, preds, \n",
        "                                   target_names=[le_target_final.inverse_transform([c])[0] for c in unique_classes],\n",
        "                                   zero_division=0)\n",
        "\n",
        "# Feature importance\n",
        "print(\"\\n   Top 15 Fitur Paling Penting:\")\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': available_features,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "print(feature_importance.head(15).to_string(index=False))\n",
        "\n",
        "# ==========================================\n",
        "# BAGIAN 6: PREDIKSI & EXPORT HASIL\n",
        "# ==========================================\n",
        "print(\"\\n6. Menghasilkan Prediksi Akhir...\")\n",
        "\n",
        "# Ambil data kondisi terakhir setiap customer untuk diprediksi\n",
        "X_latest = latest_status.copy()\n",
        "\n",
        "# Tambahkan fitur lanjutan untuk data prediksi\n",
        "X_latest['Year'] = X_latest[col_date].dt.year\n",
        "X_latest['Month'] = X_latest[col_date].dt.month\n",
        "X_latest['Quarter'] = X_latest[col_date].dt.quarter\n",
        "X_latest['DayOfWeek'] = X_latest[col_date].dt.dayofweek\n",
        "X_latest['IsWeekend'] = (X_latest['DayOfWeek'] >= 5).astype(int)\n",
        "\n",
        "# Customer stats untuk data prediksi\n",
        "X_latest = X_latest.merge(customer_stats, on=col_id, how='left')\n",
        "\n",
        "# Transition features\n",
        "X_latest['Transition'] = X_latest[col_prod].astype(str) + '_TO_' + X_latest['Prev_Product'].astype(str)\n",
        "X_latest['Transition_Frequency'] = X_latest['Transition'].map(transition_counts).fillna(0)\n",
        "\n",
        "# Ratios\n",
        "X_latest['Price_Ratio'] = X_latest[col_price] / (X_latest['Customer_hargaPelanggan_mean'] + 1e-6)\n",
        "X_latest['BW_Ratio'] = X_latest[col_bw] / (X_latest['Customer_bandwidthBaru_mean'] + 1e-6)\n",
        "\n",
        "# Interactions\n",
        "X_latest['Price_BW_Interaction'] = X_latest[col_price] * X_latest[col_bw]\n",
        "X_latest['Days_Order_Interaction'] = X_latest['Days_Since_Last'] * X_latest['Order_Seq']\n",
        "X_latest['Is_Repeat_Customer'] = (X_latest['Order_Seq'] > 1).astype(int)\n",
        "X_latest['Is_Long_Gap'] = (X_latest['Days_Since_Last'] > X_latest['Customer_Days_Since_Last_mean']).astype(int)\n",
        "X_latest['Segmen_SBU'] = X_latest[col_segmen].astype(str) + '_' + X_latest[col_sbu].astype(str)\n",
        "\n",
        "# NEW: Advanced features untuk prediksi\n",
        "# Rolling statistics (gunakan nilai terakhir sebagai proxy)\n",
        "X_latest['Price_Rolling_Mean_3'] = X_latest[col_price]  # Proxy: gunakan nilai saat ini\n",
        "X_latest['BW_Rolling_Mean_3'] = X_latest[col_bw]\n",
        "X_latest['Days_Rolling_Mean_3'] = X_latest['Days_Since_Last']\n",
        "\n",
        "# Product popularity\n",
        "X_latest['Product_Popularity'] = X_latest[col_prod].map(product_popularity).fillna(0)\n",
        "X_latest['Prev_Product_Popularity'] = X_latest['Prev_Product'].map(product_popularity).fillna(0)\n",
        "\n",
        "# Customer frequency\n",
        "X_latest['Customer_Frequency'] = X_latest[col_id].map(customer_frequency).fillna(1)\n",
        "\n",
        "# Time-based advanced\n",
        "X_latest['Days_Since_Year_Start'] = (X_latest[col_date] - pd.to_datetime(X_latest['Year'].astype(str) + '-01-01')).dt.days\n",
        "X_latest['Days_Since_Month_Start'] = (X_latest[col_date] - pd.to_datetime(X_latest[col_date].dt.to_period('M').astype(str))).dt.days\n",
        "X_latest['Is_Month_End'] = (X_latest[col_date].dt.day > 25).astype(int)\n",
        "X_latest['Is_Quarter_End'] = X_latest['Month'].isin([3, 6, 9, 12]).astype(int)\n",
        "\n",
        "# Price change (proxy: 0 karena tidak ada history)\n",
        "X_latest['Price_Change'] = 0\n",
        "X_latest['Price_Change_Pct'] = 0\n",
        "X_latest['BW_Change'] = 0\n",
        "\n",
        "# Customer-Product and Segment-Product affinity\n",
        "X_latest = X_latest.merge(customer_product_count, on=[col_id, col_prod], how='left')\n",
        "X_latest['Customer_Product_Count'] = X_latest['Customer_Product_Count'].fillna(0)\n",
        "X_latest = X_latest.merge(segmen_product_count, on=[col_segmen, col_prod], how='left')\n",
        "X_latest['Segmen_Product_Count'] = X_latest['Segmen_Product_Count'].fillna(0)\n",
        "\n",
        "# Normalized features\n",
        "X_latest['Order_Seq_Normalized'] = X_latest['Order_Seq'] / (X_latest['Customer_Order_Seq_max'] + 1e-6)\n",
        "X_latest['Days_Since_Last_Normalized'] = X_latest['Days_Since_Last'] / (X_latest['Customer_Days_Since_Last_mean'] + 1e-6)\n",
        "\n",
        "# Fill NaN\n",
        "X_latest = X_latest.fillna(0)\n",
        "\n",
        "# Encoding fitur untuk data prediksi (dengan error handling)\n",
        "def safe_transform(encoder, values):\n",
        "    \"\"\"Transform dengan handling untuk nilai yang tidak terlihat\"\"\"\n",
        "    result = []\n",
        "    for val in values:\n",
        "        val_str = str(val)\n",
        "        if val_str in encoder.classes_:\n",
        "            result.append(encoder.transform([val_str])[0])\n",
        "        else:\n",
        "            # Gunakan nilai default (0 atau nilai pertama)\n",
        "            result.append(0)\n",
        "    return result\n",
        "\n",
        "X_latest['prod_code'] = safe_transform(le_prod, X_latest[col_prod].astype(str))\n",
        "X_latest['prev_prod_code'] = safe_transform(le_prev_prod, X_latest['Prev_Product'].astype(str))\n",
        "X_latest['segmen_code'] = safe_transform(le_segmen, X_latest[col_segmen].astype(str))\n",
        "X_latest['sbu_code'] = safe_transform(le_sbu, X_latest[col_sbu].astype(str))\n",
        "\n",
        "# Encode interaction features (handle unseen values)\n",
        "X_latest['segmen_sbu_code'] = X_latest['Segmen_SBU'].apply(\n",
        "    lambda x: le_segmen_sbu.transform([str(x)])[0] if str(x) in le_segmen_sbu.classes_ else 0\n",
        ")\n",
        "X_latest['transition_code'] = X_latest['Transition'].apply(\n",
        "    lambda x: le_transition.transform([str(x)])[0] if str(x) in le_transition.classes_ else 0\n",
        ")\n",
        "\n",
        "# Pilih kolom fitur yang sama persis dengan saat training\n",
        "X_final_pred = X_latest[available_features].copy()\n",
        "\n",
        "# Clean data prediksi - replace inf and NaN\n",
        "X_final_pred = X_final_pred.replace([np.inf, -np.inf], np.nan)\n",
        "X_final_pred = X_final_pred.fillna(0)\n",
        "\n",
        "# Pastikan semua kolom ada\n",
        "missing_cols = set(available_features) - set(X_final_pred.columns)\n",
        "if missing_cols:\n",
        "    print(f\"   Warning: Kolom yang hilang: {missing_cols}, mengisi dengan 0...\")\n",
        "    for col in missing_cols:\n",
        "        X_final_pred[col] = 0\n",
        "\n",
        "# Pastikan urutan kolom sama dengan training\n",
        "X_final_pred = X_final_pred[available_features]\n",
        "\n",
        "# Lakukan Prediksi\n",
        "print(\"   Melakukan prediksi...\")\n",
        "pred_codes = model.predict(X_final_pred)\n",
        "\n",
        "# PENTING: Decode pakai le_target_final (yang dibuat di Bagian 4)\n",
        "pred_names = le_target_final.inverse_transform(pred_codes)\n",
        "\n",
        "# Simpan Hasil\n",
        "hasil_akhir = latest_status[[col_id, col_prod, col_segmen, col_sbu, col_date]].copy()\n",
        "hasil_akhir.rename(columns={col_prod: 'Produk_Saat_Ini', col_date: 'Tanggal_Terakhir'}, inplace=True)\n",
        "hasil_akhir['Rekomendasi_Produk_Berikutnya'] = pred_names\n",
        "hasil_akhir['Beda_ato_ngga'] = np.where(hasil_akhir['Produk_Saat_Ini'] == hasil_akhir['Rekomendasi_Produk_Berikutnya'], 'Sama', 'Beda')\n",
        "\n",
        "# Export - file akan disimpan di folder yang sama dengan notebook\n",
        "output_filename = 'Hasil_Prediksi_Flow_Fixed_2.xlsx'\n",
        "hasil_akhir.to_excel(output_filename, index=False)\n",
        "print(f\"   Selesai! File tersimpan di: {output_filename}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (.venv)",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
