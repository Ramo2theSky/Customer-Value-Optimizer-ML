{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd2d78a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# BAGIAN 1: IMPORT LIBRARY & LOAD DATA\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a6a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b5869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1801ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# BAGIAN 2: DATA PREPARATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. Load Data\n",
    "# Note: Using the provided filename \"Data Sampel 22 Januari.csv\"\n",
    "file_path = 'Data Sampel 22 Januari.csv'\n",
    "df = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "print(f\"Total Rows Raw Data: {len(df)}\")\n",
    "\n",
    "# 2. Filter Data\n",
    "# CloseLost must be 'NO' and statusLayanan must not be 'TIDAK AKTIF'\n",
    "df_filtered = df[\n",
    "    (df['CloseLost'] == 'NO') & \n",
    "    (df['statusLayanan'] != 'TIDAK AKTIF')\n",
    "].copy()\n",
    "\n",
    "print(f\"Rows after filtering: {len(df_filtered)}\")\n",
    "\n",
    "# 3. Convert Date Column\n",
    "df_filtered['tanggalBuatPermohonan'] = pd.to_datetime(df_filtered['tanggalBuatPermohonan'])\n",
    "\n",
    "# 4. Sort Data\n",
    "# Vital for history flow\n",
    "df_sorted = df_filtered.sort_values(by=['idPerusahaan', 'tanggalBuatPermohonan'])\n",
    "\n",
    "# Select relevant columns\n",
    "data = df_sorted[['idPerusahaan', 'tanggalBuatPermohonan', 'namaProduk']]\n",
    "\n",
    "display(data.head())\n",
    "print(f\"Number of unique customers: {data['idPerusahaan'].nunique()}\")\n",
    "print(f\"Number of unique products: {data['namaProduk'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16735d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# BAGIAN 3: SEQUENCE GENERATION\n",
    "# ==========================================\n",
    "\n",
    "# 1. Group by Customer and get list of products in chronological order\n",
    "customer_history = data.groupby('idPerusahaan')['namaProduk'].apply(list).reset_index()\n",
    "\n",
    "# Filter out customers with only 1 purchase (cannot train sequence)\n",
    "customer_history = customer_history[customer_history['namaProduk'].apply(len) > 1]\n",
    "print(f\"Customers with > 1 purchase: {len(customer_history)}\")\n",
    "\n",
    "# 2. Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(customer_history['namaProduk'])\n",
    "total_products = len(tokenizer.word_index) + 1  # 1 for padding\n",
    "\n",
    "print(f\"Total Unique Products (Vocab Size): {total_products}\")\n",
    "\n",
    "# Convert product names to sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(customer_history['namaProduk'])\n",
    "\n",
    "# 3. Create N-Gram Sequences\n",
    "# For [A, B, C] -> Input: [A], Label: B; Input: [A, B], Label: C\n",
    "input_sequences = []\n",
    "for seq in sequences:\n",
    "    for i in range(1, len(seq)):\n",
    "        n_gram_sequence = seq[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "print(f\"Total Input Sequences generated: {len(input_sequences)}\")\n",
    "print(\"Example sequences (tokens):\", input_sequences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da46c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# BAGIAN 4: PADDING & SPLITTING\n",
    "# ==========================================\n",
    "\n",
    "# 1. Padding\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "print(f\"Max Sequence Length: {max_sequence_len}\")\n",
    "\n",
    "padded_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "# 2. Split X and y\n",
    "X = padded_sequences[:, :-1]\n",
    "y = padded_sequences[:, -1]\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# 3. Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# BAGIAN 5: MODEL ARCHITECTURE\n",
    "# ==========================================\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding Layer\n",
    "# input_dim needs to be total_products\n",
    "# input_length is max_sequence_len - 1 (because we took last token as label)\n",
    "model.add(Embedding(input_dim=total_products, \n",
    "                    output_dim=64, \n",
    "                    input_length=max_sequence_len - 1))\n",
    "\n",
    "# LSTM Layer\n",
    "model.add(LSTM(100, dropout=0.2))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(total_products, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f2e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# BAGIAN 6: TRAINING\n",
    "# ==========================================\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=50, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)\n",
    "\n",
    "print(\"Training Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef9794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# BAGIAN 7: VISUALIZATION\n",
    "# ==========================================\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# BAGIAN 8: INFERENCE FUNCTION & SAVING\n",
    "# ==========================================\n",
    "import json\n",
    "\n",
    "# Save Tokenizer logic\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "print(\"Tokenizer saved as tokenizer.json\")\n",
    "\n",
    "# Save Model (Optional but good practice)\n",
    "model.save(\"lstm_product_recommendation.h5\")\n",
    "print(\"Model saved as lstm_product_recommendation.h5\")\n",
    "\n",
    "def recommend_next_product(customer_id, top_k=3):\n",
    "    \"\"\"\n",
    "    Predicts the next top_k most likely products for a given customer_id.\n",
    "    \"\"\"\n",
    "    # 1. Get Customer History\n",
    "    customer_data = df_filtered[df_filtered['idPerusahaan'] == customer_id].sort_values('tanggalBuatPermohonan')\n",
    "    \n",
    "    if len(customer_data) == 0:\n",
    "        return \"Customer ID not found or has no valid purchase history.\"\n",
    "    \n",
    "    product_history = customer_data['namaProduk'].tolist()\n",
    "    \n",
    "    # 2. Prepare Sequence\n",
    "    token_list = tokenizer.texts_to_sequences([product_history])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    \n",
    "    # 3. Predict\n",
    "    predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "    \n",
    "    # Get Top K indices\n",
    "    top_indices = predicted_probs.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    recommendations = []\n",
    "    for idx in top_indices:\n",
    "        # Decode index to word (product name)\n",
    "        # tokenizer.index_word contains the mapping from integer to string\n",
    "        if idx in tokenizer.index_word:\n",
    "            product_name = tokenizer.index_word[idx]\n",
    "            probability = predicted_probs[idx]\n",
    "            recommendations.append((product_name, probability))\n",
    "            \n",
    "    return {\n",
    "        \"customer_id\": customer_id,\n",
    "        \"history_length\": len(product_history),\n",
    "        \"last_purchases\": product_history[-5:], # Show last 5\n",
    "        \"recommendations\": recommendations\n",
    "    }\n",
    "\n",
    "print(\"Inference function ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# BAGIAN 9: TEST PREDICTION\n",
    "# ==========================================\n",
    "\n",
    "# Pick a random customer from the history\n",
    "sample_customer_id = customer_history['idPerusahaan'].sample(1).values[0]\n",
    "\n",
    "print(f\"Testing recommendation for Customer ID: {sample_customer_id}\")\n",
    "result = recommend_next_product(sample_customer_id)\n",
    "\n",
    "print(\"\\n--- Recommendation Result ---\")\n",
    "print(f\"Customer ID: {result['customer_id']}\")\n",
    "print(f\"History (Last 5): {result['last_purchases']}\")\n",
    "print(\"\\nPredicted Next Best Products:\")\n",
    "for i, (prod, prob) in enumerate(result['recommendations'], 1):\n",
    "    print(f\"{i}. {prod} (Confidence: {prob:.2%})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "balenciaga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
